{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c3a4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37495f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes loaded: 2481\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“˜ Step 2: Load Cleaned Resumes\n",
    "df = pd.read_csv('../data/cleaned_resumes.csv')\n",
    "df.head()\n",
    "df.dropna(subset=['cleaned_resume', 'Category'], inplace=True)\n",
    "print(f\"Total resumes loaded: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ee967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes loaded: 100\n",
      "Encoding top 100 resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:10<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“˜ Step 2: Take Only Top 100 Resumes\n",
    "df = df.head(100)\n",
    "print(f\"Total resumes loaded: {len(df)}\")  # Should print 100\n",
    "# ðŸ“˜ Step 3: Load SBERT Model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# ðŸ“˜ Step 4: Encode Top 100 Resumes\n",
    "print(\"Encoding top 100 resumes...\")\n",
    "resume_embeddings = model.encode(df['cleaned_resume'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# ðŸ“˜ Step 5: Input a Sample JD\n",
    "sample_jd = \"\"\"\n",
    "Looking for a Data Scientist with strong Python, machine learning, and NLP skills.\n",
    "Experience with resume parsing, vector embeddings, and model deployment is a plus.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f424ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matching resumes saved to 'output/top_resume_matches.csv' âœ…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jd_embedding = model.encode([sample_jd])\n",
    "\n",
    "# ðŸ“˜ Step 6: Compute Cosine Similarities\n",
    "cosine_scores = cosine_similarity(jd_embedding, resume_embeddings)[0]\n",
    "\n",
    "# ðŸ“˜ Step 7: Rank Resumes\n",
    "df['similarity_score'] = cosine_scores\n",
    "top_matches = df.sort_values(by='similarity_score', ascending=False).head(10)\n",
    "\n",
    "# ðŸ“˜ Step 8: Save Results\n",
    "top_matches.to_csv('../output/top_resume_matches.csv', index=False)\n",
    "print(\"Top matching resumes saved to 'output/top_resume_matches.csv' âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b218e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
